{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for a few decades, and is a major force in popular culture.\n",
    "\n",
    "Let's say we want to compete on Jeopardy, and we're looking for any edge we can get to win. In this project, we'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help you win."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The dataset is named `jeopardy.csv`, and contains 20000 rows from the beginning of a full dataset of Jeopardy questions, which you can download [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file). \n",
    "\n",
    "We'll import needed modules, read the data in, and have a quick look next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>U.S. GEOGRAPHY</td>\n",
       "      <td>$200</td>\n",
       "      <td>Of 8, 12 or 18, the number of U.S. states that...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>POP MUSIC PAIRINGS</td>\n",
       "      <td>$200</td>\n",
       "      <td>...&amp; the New Power Generation</td>\n",
       "      <td>Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORIC PEOPLE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>Galileo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>1998 QUOTATIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Before the grand jury she said, \"I'm really so...</td>\n",
       "      <td>Monica Lewinsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LLAMA-RAMA</td>\n",
       "      <td>$200</td>\n",
       "      <td>Llamas are the heftiest South American members...</td>\n",
       "      <td>Camels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Show Number    Air Date      Round                         Category  \\\n",
       "0             4680  2004-12-31  Jeopardy!                          HISTORY   \n",
       "1             4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   \n",
       "2             4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   \n",
       "3             4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   \n",
       "4             4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   \n",
       "...            ...         ...        ...                              ...   \n",
       "19994         3582  2000-03-14  Jeopardy!                   U.S. GEOGRAPHY   \n",
       "19995         3582  2000-03-14  Jeopardy!               POP MUSIC PAIRINGS   \n",
       "19996         3582  2000-03-14  Jeopardy!                  HISTORIC PEOPLE   \n",
       "19997         3582  2000-03-14  Jeopardy!                  1998 QUOTATIONS   \n",
       "19998         3582  2000-03-14  Jeopardy!                       LLAMA-RAMA   \n",
       "\n",
       "       Value                                           Question  \\\n",
       "0       $200  For the last 8 years of his life, Galileo was ...   \n",
       "1       $200  No. 2: 1912 Olympian; football star at Carlisl...   \n",
       "2       $200  The city of Yuma in this state has a record av...   \n",
       "3       $200  In 1963, live on \"The Art Linkletter Show\", th...   \n",
       "4       $200  Signer of the Dec. of Indep., framer of the Co...   \n",
       "...      ...                                                ...   \n",
       "19994   $200  Of 8, 12 or 18, the number of U.S. states that...   \n",
       "19995   $200                      ...& the New Power Generation   \n",
       "19996   $200  In 1589 he was appointed professor of mathemat...   \n",
       "19997   $200  Before the grand jury she said, \"I'm really so...   \n",
       "19998   $200  Llamas are the heftiest South American members...   \n",
       "\n",
       "                Answer  \n",
       "0           Copernicus  \n",
       "1           Jim Thorpe  \n",
       "2              Arizona  \n",
       "3           McDonald's  \n",
       "4           John Adams  \n",
       "...                ...  \n",
       "19994               18  \n",
       "19995           Prince  \n",
       "19996          Galileo  \n",
       "19997  Monica Lewinsky  \n",
       "19998           Camels  \n",
       "\n",
       "[19999 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "\n",
    "jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each row in the dataset represents a single question on a single episode of Jeopardy. Here are explanations of each column:\n",
    "\n",
    " - `Show Number` -- the Jeopardy episode number of the show this question was in.\n",
    " \n",
    " - `Air Date` -- the date the episode aired.\n",
    " \n",
    " - `Round` -- the round of Jeopardy that the question was asked in. Jeopardy has several rounds as each episode progresses.\n",
    " \n",
    " - `Category` -- the category of the question.\n",
    " \n",
    " - `Value` -- the number of dollars answering the question correctly is worth.\n",
    " \n",
    " - `Question` -- the text of the question.\n",
    " \n",
    " - `Answer` -- the text of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Show Number                int64\n",
       "Air Date          datetime64[ns]\n",
       "Round                     object\n",
       "Category                  object\n",
       "Value                     object\n",
       "Question                  object\n",
       "Answer                    object\n",
       "clean_question            object\n",
       "clean_answer              object\n",
       "clean_value                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also detect that some of the column names have extra spaces, we'll remove those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Text\n",
    "\n",
    "We'll now normalize the text, basically changing to lower case and removing punctuation. \n",
    "\n",
    "Steps: \n",
    "\n",
    " - Write a function to normalize questions and answers. It should:\n",
    " \n",
    " - Take in a string.\n",
    " - Convert the string to lowercase.\n",
    " - Remove all punctuation in the string.\n",
    " - Return the string.\n",
    " - Normalize the `Question` column.\n",
    " - Use the Pandas `Series.apply` method to apply the function to each item in the `Question` column.\n",
    " - Assign the result to the `clean_question` column.\n",
    " - Normalize the `Answer` column.\n",
    " - Use the Pandas `Series.apply` method to apply the function to each item in the `Answer` column.\n",
    " - Assign the result to the `clean_answer` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def normalize_values(text):\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception:\n",
    "        text = 0\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(normalize_text)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].apply(normalize_text)\n",
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(normalize_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>U.S. GEOGRAPHY</td>\n",
       "      <td>$200</td>\n",
       "      <td>Of 8, 12 or 18, the number of U.S. states that...</td>\n",
       "      <td>18</td>\n",
       "      <td>of 8 12 or 18 the number of us states that tou...</td>\n",
       "      <td>18</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>POP MUSIC PAIRINGS</td>\n",
       "      <td>$200</td>\n",
       "      <td>...&amp; the New Power Generation</td>\n",
       "      <td>Prince</td>\n",
       "      <td>the new power generation</td>\n",
       "      <td>prince</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORIC PEOPLE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>Galileo</td>\n",
       "      <td>in 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>galileo</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>1998 QUOTATIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Before the grand jury she said, \"I'm really so...</td>\n",
       "      <td>Monica Lewinsky</td>\n",
       "      <td>before the grand jury she said im really sorry...</td>\n",
       "      <td>monica lewinsky</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LLAMA-RAMA</td>\n",
       "      <td>$200</td>\n",
       "      <td>Llamas are the heftiest South American members...</td>\n",
       "      <td>Camels</td>\n",
       "      <td>llamas are the heftiest south american members...</td>\n",
       "      <td>camels</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Show Number    Air Date      Round                         Category  \\\n",
       "0             4680  2004-12-31  Jeopardy!                          HISTORY   \n",
       "1             4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   \n",
       "2             4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   \n",
       "3             4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   \n",
       "4             4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   \n",
       "...            ...         ...        ...                              ...   \n",
       "19994         3582  2000-03-14  Jeopardy!                   U.S. GEOGRAPHY   \n",
       "19995         3582  2000-03-14  Jeopardy!               POP MUSIC PAIRINGS   \n",
       "19996         3582  2000-03-14  Jeopardy!                  HISTORIC PEOPLE   \n",
       "19997         3582  2000-03-14  Jeopardy!                  1998 QUOTATIONS   \n",
       "19998         3582  2000-03-14  Jeopardy!                       LLAMA-RAMA   \n",
       "\n",
       "      Value                                           Question  \\\n",
       "0      $200  For the last 8 years of his life, Galileo was ...   \n",
       "1      $200  No. 2: 1912 Olympian; football star at Carlisl...   \n",
       "2      $200  The city of Yuma in this state has a record av...   \n",
       "3      $200  In 1963, live on \"The Art Linkletter Show\", th...   \n",
       "4      $200  Signer of the Dec. of Indep., framer of the Co...   \n",
       "...     ...                                                ...   \n",
       "19994  $200  Of 8, 12 or 18, the number of U.S. states that...   \n",
       "19995  $200                      ...& the New Power Generation   \n",
       "19996  $200  In 1589 he was appointed professor of mathemat...   \n",
       "19997  $200  Before the grand jury she said, \"I'm really so...   \n",
       "19998  $200  Llamas are the heftiest South American members...   \n",
       "\n",
       "                Answer                                     clean_question  \\\n",
       "0           Copernicus  for the last 8 years of his life galileo was u...   \n",
       "1           Jim Thorpe  no 2 1912 olympian football star at carlisle i...   \n",
       "2              Arizona  the city of yuma in this state has a record av...   \n",
       "3           McDonald's  in 1963 live on the art linkletter show this c...   \n",
       "4           John Adams  signer of the dec of indep framer of the const...   \n",
       "...                ...                                                ...   \n",
       "19994               18  of 8 12 or 18 the number of us states that tou...   \n",
       "19995           Prince                           the new power generation   \n",
       "19996          Galileo  in 1589 he was appointed professor of mathemat...   \n",
       "19997  Monica Lewinsky  before the grand jury she said im really sorry...   \n",
       "19998           Camels  llamas are the heftiest south american members...   \n",
       "\n",
       "          clean_answer  clean_value  \n",
       "0           copernicus          200  \n",
       "1           jim thorpe          200  \n",
       "2              arizona          200  \n",
       "3            mcdonalds          200  \n",
       "4           john adams          200  \n",
       "...                ...          ...  \n",
       "19994               18          200  \n",
       "19995           prince          200  \n",
       "19996          galileo          200  \n",
       "19997  monica lewinsky          200  \n",
       "19998           camels          200  \n",
       "\n",
       "[19999 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing other columns\n",
    "\n",
    "The Value column should be numeric, to allow easier manipulation. We need to remove the dollar sign from the beginning of each value and convert the column from text to numeric.\n",
    "\n",
    "Steps: \n",
    " - Write a function to normalize dollar values. It should:\n",
    "   - Take in a string.\n",
    "   - Remove any punctuation in the string.\n",
    "   - Convert the string to an integer.\n",
    "   - If the conversion has an error, assign 0 instead.\n",
    "   - Return the integer.\n",
    "\n",
    "The Air Date column should be converted to a datetime from a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy[\"Air Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Show Number                int64\n",
       "Air Date          datetime64[ns]\n",
       "Round                     object\n",
       "Category                  object\n",
       "Value                     object\n",
       "Question                  object\n",
       "Answer                    object\n",
       "clean_question            object\n",
       "clean_answer              object\n",
       "clean_value                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers to Questions\n",
    "\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    " - How often the answer is deducible from the question.\n",
    " - How often new questions are repeats of older questions.\n",
    " \n",
    "You can answer the second question by seeing how often complex words (> 6 characters) reoccur. You can answer the first question by seeing how many times words in the answer also occur in the question. We'll work on the first question now, and come back to the second.\n",
    "\n",
    "Steps:\n",
    "\n",
    " - Write a function that takes in a row in jeopardy, as a Series. It should:\n",
    "   - Split the `clean_answer` column around spaces and assign to the variable `split_answer`.\n",
    "   - Split the `clean_question` column around spaces and assign to the variable `split_question`.\n",
    "   - Create a variable called `match_count`, and set it to `0`.\n",
    "   - If `the` is in `split_answer`, remove it using the `remove` method on lists. `The` is commonly found in answers and questions, but doesn't have any meaningful use in finding the answer.\n",
    "   - If the length of `split_answer` is 0, return 0. This prevents a division by zero error later.\n",
    "   - Loop through each item in `split_answer`, and see if it occurs in `split_question`. If it does, add 1 to `match_count`.\n",
    "   - Divide `match_count` by the length of `split_answer`, and return the result.\n",
    "   - Count how many times terms in `clean_answer` occur in `clean_question`.\n",
    "   - Use the Pandas `DataFrame.apply` method to apply the function to each row in jeopardy.\n",
    "   - Pass the `axis=1` argument to apply the function across each row.\n",
    "   - Assign the result to the `answer_in_question` column.\n",
    "   \n",
    "   \n",
    "- Find the mean of the `answer_in_question` column using the `mean` method on Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(row):\n",
    "    split_answer = row[\"clean_answer\"].split(\" \")\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    match_count = 0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060493257069335914"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"answer_in_question\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer terms in the question\n",
    "\n",
    "The answer only appears in the question about `6%` of the time.  This isn't a huge number, and means that we probably can't just hope that hearing a question will enable us to figure out the answer.  We'll probably have to study.\n",
    "\n",
    "Let's say we want to investigate how often new questions are repeats of older ones. We can't completely answer this, because we only have about 10% of the full Jeopardy question dataset, but we can investigate it at least.\n",
    "\n",
    "To do this, we can:\n",
    "\n",
    " - Sort jeopardy in order of ascending air date.\n",
    " - Maintain a set called `terms_used` that will be empty initially.\n",
    " - Iterate through each row of jeopardy.\n",
    " - Split `clean_question` into words, remove any word shorter than 6 characters, and check if each word occurs in `terms_used`.\n",
    " - If it does, increment a counter.\n",
    " - Add each word to `terms_used`.\n",
    "\n",
    "This will enable us to check if the terms in questions have been used previously or not. Only looking at words greater than 6 characters enables us to filter out words like `the` and `than`, which are commonly used, but don't tell us a lot about a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6876260592169776"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values(\"Air Date\")\n",
    "\n",
    "for i, row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split(\" \")\n",
    "        split_question = [q for q in split_question if len(q) > 5]\n",
    "        match_count = 0\n",
    "        for word in split_question:\n",
    "            if word in terms_used:\n",
    "                match_count += 1\n",
    "        for word in split_question:\n",
    "            terms_used.add(word)\n",
    "        if len(split_question) > 0:\n",
    "            match_count /= len(split_question)\n",
    "        question_overlap.append(match_count)\n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "\n",
    "jeopardy[\"question_overlap\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is about `70%` overlap between terms in new questions and terms in old questions.  This only looks at a small set of questions, and it doesn't look at phrases, it looks at single terms.  This makes it relatively insignificant, but it does mean that it's worth looking more into the recycling of questions.\n",
    "\n",
    "\n",
    "### Low value vs high value questions\n",
    "\n",
    "Let's say we only want to study questions that pertain to high value questions instead of low value questions. This will help us earn more money on Jeopardy.\n",
    "\n",
    "We can figure out which terms correspond to high-value questions using a chi-squared test. we'll first need to narrow down the questions into two categories:\n",
    "\n",
    " - Low value -- Any row where Value is less than 800.\n",
    " - High value -- Any row where Value is greater than 800.\n",
    "You'll then be able to loop through each of the terms from the last screen, `terms_used`, and:\n",
    "\n",
    " - Find the number of low value questions the word occurs in.\n",
    " - Find the number of high value questions the word occurs in.\n",
    " - Find the percentage of questions the word occurs in.\n",
    " - Based on the percentage of questions the word occurs in, find expected counts.\n",
    " - Compute the chi squared value based on the expected counts and the observed counts for high and low value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a row from a Dataframe\n",
    "def determine_value(row):\n",
    "    \n",
    "    value = 0\n",
    "    \n",
    "    # clean_value column is greater than 800\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        \n",
    "        # Assign 1\n",
    "        value = 1\n",
    "        \n",
    "        # Otherwise 0\n",
    "    return value\n",
    "\n",
    "# apply the function to each row in jeopardy\n",
    "jeopardy[\"high_value\"] = jeopardy.apply(determine_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 0), (1, 0), (1, 0), (4, 5)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# takes in a word\n",
    "def count_usage(term):\n",
    "    \n",
    "    # set counters to 0\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    \n",
    "    # Loops through each row in jeopardy with iterrows \n",
    "    for i, row in jeopardy.iterrows():\n",
    "        \n",
    "        # Split the clean_question column on the space character \n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            \n",
    "            # If the word is in the split question\n",
    "            # If the high_value column is 1, \n",
    "            if row[\"high_value\"] == 1:\n",
    "                \n",
    "                # add 1 to high_count\n",
    "                high_count += 1\n",
    "            \n",
    "            # otherwise increment low_count\n",
    "            else:\n",
    "                low_count += 1\n",
    "    \n",
    "    return high_count, low_count\n",
    "\n",
    "# Convert terms_used into a list using the list function, \n",
    "# and assign the first 5 elements to comparison_terms\n",
    "comparison_terms = list(terms_used)[:5]\n",
    "\n",
    "# Create an empty list called observed_expected\n",
    "observed_expected = []\n",
    "\n",
    "# Loop through each term in comparison_terms\n",
    "for term in comparison_terms:\n",
    "    \n",
    "    # apply the function to each term to get the high value and low value counts\n",
    "    # and append to the list result to observed_expected\n",
    "    observed_expected.append(count_usage(term))\n",
    "\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the chi-squared test\n",
    "\n",
    "Now that we've found the observed counts for a few terms, we can compute the expected counts and the chi-squared value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.03188116723440362, pvalue=0.8582887163235293),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=1.094860558700322, pvalue=0.2953967699181073)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "# Find the number of rows in jeopardy where high_value is 1, assign to high_value_count\n",
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "\n",
    "# Find the number of rows in jeopardy where high_value is 0, and assign to low_value_count\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "# Create an empty list called chi_squared\n",
    "chi_squared = []\n",
    "\n",
    "# Loop through each list in observed_expected\n",
    "for obs in observed_expected:\n",
    "    \n",
    "    # Get the total count\n",
    "    # Add up both items in the list (high and low counts) \n",
    "    # assign to total\n",
    "    total = sum(obs)\n",
    "    \n",
    "    # Get the proportion across the dataset\n",
    "    # Divide total by the number of rows in jeopardy \n",
    "    # Assign to total_prop\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    \n",
    "    # Get the expected term count for high value rows\n",
    "    # Multiply total_prop by high_value_count   \n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    \n",
    "    # Get the expected term count for low value rows\n",
    "    # Multiply total_prop by low_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    \n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    \n",
    "    # Use scipy.stats.chisquare to compute the chi-squared value \n",
    "    # and p-value given the expected and observed counts.\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared results\n",
    "\n",
    "None of the terms had a significant difference in usage between high value and low value rows.  Additionally, the frequencies were all lower than `5`, so the chi-squared test isn't as valid.  It would be better to run this test with only terms that have higher frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
